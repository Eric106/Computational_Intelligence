{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pandas import DataFrame, read_parquet, read_csv\n",
        "from datetime import datetime as dt\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from time import time\n",
        "from os import listdir\n",
        "import sys\n",
        "\n",
        "def get_random_sample_data(data: DataFrame, test_ratio: float):\n",
        "    ''' permutation: Randomly permute a sequence or return a permuted range (ndarray).\n",
        "                    If x is a multi-dimensional array, it is only shuffled along its first index.'''\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    # return the \u201cx-first\u201d values\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    return data.iloc[test_indices]\n",
        "\n",
        "\n",
        "def log_to_parquet(in_file: str, out_file: str, file_cols: list, parquet_engine: str):\n",
        "    # LOAD DATA FROM A LOG FILE AND SAVE IT ON A PARQUET FILE TO IMPROVE PERFORMANCE AT READING THE DATA\n",
        "    df = read_csv(in_file, sep=\"\\t\", header=None,\n",
        "                  names=file_cols, low_memory=False)\n",
        "    df.to_parquet(out_file, index=False, engine=parquet_engine)\n",
        "    del df\n",
        "\n",
        "\n",
        "def get_files_inFolder(folder: str, fileType: str):\n",
        "    return list(filter(lambda fileName: \n",
        "                            fileName[-len(fileType):] == fileType,\n",
        "                        listdir(folder)))\n",
        "#---------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def conn_analysis(log_file: str, sample_data: bool):\n",
        "\n",
        "    list_log_files = get_files_inFolder(\"./\",\"log\")\n",
        "    list_parq_files = get_files_inFolder(\"./\",\"parq\")\n",
        "    complete_name_f = log_file.split('.log')[0]+'.parq'\n",
        "    sample_name_f = log_file.split('.log')[0]+'_sample.parq'\n",
        "    P_ENGINE = \"pyarrow\"\n",
        "    SAMPLE_SIZE = 0.10\n",
        "    df = None\n",
        "    if not (complete_name_f in list_parq_files):\n",
        "        if not log_file in list_log_files:\n",
        "            print(\"ERROR fileNotFound: \"+log_file)\n",
        "            return \n",
        "        try:\n",
        "            log_col_names = [\"ts\", \"uid\", \"id_orig_h\", \"id_orig_p\", \"id_resp_h\", \"id_resp_p\", \"proto\", \"service\", \"duration\", \"orig_bytes\", \"resp_bytes\",\n",
        "                            \"conn_state\", \"local_orig\", \"missed_bytes\", \"history\", \"orig_pkts\", \"orig_ip_bytes\", \"resp_pkts\", \"resp_ip_bytes\", \"tunnel_parents\"]\n",
        "            log_to_parquet(in_file=log_file, out_file=complete_name_f,\n",
        "                            file_cols=log_col_names, parquet_engine=P_ENGINE)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return\n",
        "    if sample_data and (not sample_name_f in list_parq_files):\n",
        "        complete_df = read_parquet(complete_name_f, engine=P_ENGINE)\n",
        "        sample_df = get_random_sample_data(complete_df, SAMPLE_SIZE)\n",
        "        del complete_df\n",
        "        sample_df.to_parquet(sample_name_f, index=False, engine=P_ENGINE)\n",
        "        del sample_df\n",
        "\n",
        "    df = read_parquet(sample_name_f) if sample_data else read_parquet(complete_name_f)\n",
        "\n",
        "    df[\"ts\"] = list(map(\n",
        "                    lambda date: \n",
        "                        dt.fromtimestamp(float(date)),\n",
        "                    df[\"ts\"].tolist()))\n",
        "    df[\"duration\"] = list(map(\n",
        "                        lambda dur: \n",
        "                            float(dur) if not \"-\" in dur else 0.0,\n",
        "                        df[\"duration\"].tolist()))\n",
        "    print(df.info())\n",
        "\n",
        "    important_cols = [\"ts\",\"uid\" ,\"id_orig_h\", \"id_resp_p\", \"duration\"]\n",
        "\n",
        "    df_not_web_port = df[(df[\"id_resp_p\"] != 80) &\n",
        "                         (df[\"id_resp_p\"] != 8080)]\n",
        "\n",
        "    print('\\n', \"Not http ports: \")\n",
        "    pprint(df_not_web_port[important_cols])\n",
        "\n",
        "    df_gp_not_web_port = df_not_web_port.groupby(\n",
        "        important_cols[2:4]).size().to_frame().reset_index()\n",
        "    df_gp_not_web_port.rename(columns={0: \"count\"}, inplace=True)\n",
        "    df_gp_not_web_port.sort_values(by=\"count\", ascending=False, inplace=True)\n",
        "\n",
        "    print('\\n', \"Not http ports groupby: \")\n",
        "    pprint(df_gp_not_web_port)\n",
        "\n",
        "    df_long_conn = df[df[\"duration\"] > 5]\n",
        "    df_long_conn = df_long_conn.sort_values(by=\"duration\", ascending=False)\n",
        "    print('\\n', \"Long duration connections: \")\n",
        "    pprint(df_long_conn[important_cols])\n",
        "\n",
        "\n",
        "def main():\n",
        "    intiTime = time()\n",
        "\n",
        "    # conn_analysis(log_file=\"conn.log\", sample_data=False)\n",
        "    conn_analysis(log_file=\"conn.log\", sample_data=True)\n",
        "\n",
        "    elapsedTime = round(time()-intiTime, 2)\n",
        "    elapsedTime = str(elapsedTime/60) + \\\n",
        "        \"m\" if elapsedTime >= 60 else str(elapsedTime)+\"s\"\n",
        "    print(\"\\nTiempo del proceso --->\", elapsedTime)\n",
        "    sys.exit()\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}