# ACT 3 - Anomalous Detection LSTM

    Eric GÃ³mez - A01378838
    Felipe Osornio - A01377154
    Rafael Moreno - A01378916
    Uriel Pineda - A01379633
    Hector Hernandez - A01374009

---

## Introduction

To this task, a comparison was made between two anomalous detection system using a dataset of vibration sensor readings used by the NASA Acoustics and Vibration Database. The analysis was made using the ARIMA and the Long Short-Term Memory. This latter is an artificial recurrent neural network arquitecture that is well-suited to classifying, processing and making pediction based on time series data.

In addition, the execution time, CPU consumption and the accuracy that existed between each of them were measured. This comparison is important because the ARIMA focuses mainly on obtaining results using some statistical techniques; such as variation and regression. While in the case of the LSTM, its main function is to execute epochs. Epochs are iterations through the entire neural network that are dedicated to defining the entire batch training data set. It is also important to mention that the size of the batch depends on how many item / values there are within it.

---

## Methodology

Of this first part we implemented the ARIMA and the LSTM to make the anomalous detection inside the vibration sensor dataset. The most important improvement in this part was the modularity refactoring between the algorithms calls ([ARIMA](https://github.com/Eric106/Computational_Intelligence/blob/d9151ab20aad06b439874f99e4781e93a03341ae/Act3-Anomalous_Detection_LSTM/anomalous_detection.py#L59), [LSTM](https://github.com/Eric106/Computational_Intelligence/blob/d9151ab20aad06b439874f99e4781e93a03341ae/Act3-Anomalous_Detection_LSTM/anomalous_detection.py#L84))  and the parameters ([ARIMA](https://github.com/Eric106/Computational_Intelligence/blob/d9151ab20aad06b439874f99e4781e93a03341ae/Act3-Anomalous_Detection_LSTM/anomalous_detection.py#L49), [LSTM](https://github.com/Eric106/Computational_Intelligence/blob/d9151ab20aad06b439874f99e4781e93a03341ae/Act3-Anomalous_Detection_LSTM/anomalous_detection.py#L72)). 

After that, we compare the execution time and CPU consumption of these two anomalous detection systems during the training and the predition. 

### Execution time 

```python
def exec_time(func, args:list) -> str:
    '''
    Function that measures execution time of a given function
    '''
    intiTime = time()
    try:
        func(*args)
    except Exception as e:
        print('ERROR: ',e)
    elapsedTime = round(time()-intiTime, 2)
    return str(elapsedTime)+'s'
```

### CPU consumption

```python
def get_cpu_utilization() -> Thread:

    def cpu_util():
        cpu_data = []
        while(not IS_Process_end):
            sleep(1)
            cpu_data.append(cpu_percent())
        print('CPU utilization: ', round(mean(cpu_data),2),'%')

    return Thread(
        target=cpu_util
    )
```

In addition to measuring performance in terms of runtime and CPU consumption, the accuracy between the two models was also compared and measured using the minimum loss error function. In the case of ARIMA, as it's a statistical and iterative model; an optimal predicted standard deviation was obtained. Even as can be seen in the [following graph](#figure-1) the bearing was adjusted until a stable pattern was found.

#### Figure 1

![alt text](https://github.com/Eric106/Computational_Intelligence/blob/master/Act3-Anomalous_Detection_LSTM/img/forecast.bearing.png?raw=true)

In the case of LSTM, in order to optimize its accuracy, the information was normalized to avoid a considerable difference between one value and another. Likewise, 70% of the dataset was taken for training with a batch size of 80, leaving the training in 40 epochs and a number of 9 iterations for each epoch.

FInally, to the case of the LSTM the following two graphs were obtained: 

#### Figure 2

![alt text](https://github.com/Eric106/Computational_Intelligence/blob/master/Act3-Anomalous_Detection_LSTM/img/cpu.plot.model.result.png?raw=true)

#### Figure 3

![alt text](https://github.com/Eric106/Computational_Intelligence/blob/master/Act3-Anomalous_Detection_LSTM/img/cpu.plot.training.result.png?raw=true)

---

## Finds

```python
CPU utilization:  21.72 %
All dataset average:  0.081
Predicted dataset average:  0.104
All dataset st_deviation:  0.0402
Predicted dataset st_deviation:  0.0308
ARIMA TIME:  87.1 s
```

```python
CPU utilization:  60.42 %
All dataset average:  0.081
Predicted dataset average:  0.9853
All dataset st_deviation:  0.0402
Predicted dataset st_deviation:  1.4887
LSTM TIME: 60.54 s
```

- LSTM epoch\*2 >= batch_size >= epoch
- comparaciones outputs
  <> +batch_size mayor ruido y menor tiempo de procesamiento por cada item/value
  <> -batch_size menor ruido pero mayor tiempo de procesamiento por cada item/value
  <> LSTM +cpu -exec_time
  <> ARIMA -cpu +exec_time
  <> fig1.LSTM +epoch -(minimum loss error function) --> +epochs mayor precision
  <> fi2.LSTM +good prediction
  <> ARIMA(classical inference PML) la prediccion tiene unos datos menos dispersos (std_dev) y el promedio de valore es mas parecida al dataset original
  <> LSTM la prediccion arroja datos mas dispersos y en promedio tiene valores mas altos que el dataset original.

---

## Conclusion

- ARIMA tiende a generar valores estimados menos dispersos y un poco mas acercados al data set original, debido a que es un metodo de inferencia clasica.
- LSTM jala pero entre mas epochs le pongas mayor sera la presicion
- para un analisis inicial de anomalias es una buena herramienta ya que puedes darte una buen idea con pocas "epochs"
- y lo unico negativo seria que el LSTM consume mas 'cpu' que ARIMA
